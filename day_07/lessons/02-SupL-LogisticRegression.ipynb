{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "\n",
    "When data scientists may come across a new classification problem, the first algorithm that may come across their mind is **Logistic Regression**. It is a supervised learning classification algorithm which is used to predict observations to a discrete set of classes. Practically, it is used to classify observations into different categories. Hence, its output is discrete in nature. **Logistic Regression** is also called **Logit Regression**. It is one of the most simple, straightforward and versatile classification algorithms which is used to solve classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression intuition\n",
    "\n",
    "In statistics, the **Logistic Regression model** is a widely used statistical model which is primarily used for classification purposes. It means that given a set of observations, Logistic Regression algorithm helps us to classify these observations into two or more discrete classes. So, the target variable is discrete in nature.\n",
    "\n",
    "\n",
    "The Logistic Regression algorithm works as follows -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implement linear equation**\n",
    "\n",
    "\n",
    "Logistic Regression algorithm works by implementing a linear equation with independent or explanatory variables to predict a response value. For example, we consider the example of number of hours studied and probability of passing the exam. Here, number of hours studied is the explanatory variable and it is denoted by x1. Probability of passing the exam is the response or target variable and it is denoted by z.\n",
    "\n",
    "\n",
    "If we have one explanatory variable (x1) and one response variable (z), then the linear equation would be given mathematically with the following equation-\n",
    "\n",
    "$z = \\beta_0 + \\beta_1x_1$   \n",
    "\n",
    "Here, the coefficients Î²0 and Î²1 are the parameters of the model.\n",
    "\n",
    "\n",
    "If there are multiple explanatory variables, then the above equation can be extended to\n",
    "\n",
    "$z = \\beta_0 + \\beta_1x_1+ \\beta_2x_2 + â€¦ + \\beta_nx_n$\n",
    "    \n",
    "Here, the coefficients $\\beta_0$, $\\beta_1$, $\\beta_2$ and $\\beta_n$ are the parameters of the model.\n",
    "\n",
    "So, the predicted response value is given by the above equations and is denoted by z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sigmoid Function**\n",
    "\n",
    "This predicted response value, denoted by z is then converted into a probability value that lie between 0 and 1. We use the sigmoid function in order to map predicted values to probability values. This sigmoid function then maps any real value into a probability value between 0 and 1.\n",
    "\n",
    "- In machine learning, sigmoid function is used to map predictions to probabilities. \n",
    "\n",
    "- The sigmoid function has an S shaped curve. It is also called sigmoid curve.\n",
    "\n",
    "- A Sigmoid function is a special case of the Logistic function.\n",
    "\n",
    "Graphically, we can represent sigmoid function with the following graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Function\n",
    "\n",
    "![Sigmoid Function](https://miro.medium.com/max/970/1*Xu7B5y9gp0iL5ooBj7LtWw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Decision boundary**\n",
    "\n",
    "The sigmoid function returns a probability value between 0 and 1. This probability value is then mapped to a discrete class which is either â€œ0â€ or â€œ1â€. In order to map this probability value to a discrete class (pass/fail, yes/no, true/false), we select a threshold value. This threshold value is called Decision boundary. Above this threshold value, we will map the probability values into class 1 and below which we will map values into class 0.\n",
    "\n",
    "Mathematically, it can be expressed as follows:-\n",
    "\n",
    "- p â‰¥ 0.5 => class = 1\n",
    "\n",
    "- p < 0.5 => class = 0 \n",
    "\n",
    "Generally, the decision boundary is set to 0.5. So, if the probability value is 0.8 (> 0.5), we will map this observation to class 1. Similarly, if the probability value is 0.2 (< 0.5), we will map this observation to class 0. This is represented in the graph below-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Decision boundary in sigmoid function](https://ml-cheatsheet.readthedocs.io/en/latest/_images/logistic_regression_sigmoid_w_threshold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Making predictions**\n",
    "\n",
    "Now, we know about sigmoid function and decision boundary in logistic regression. We can use our knowledge of sigmoid function and decision boundary to write a prediction function. A prediction function in logistic regression returns the probability of the observation being positive, Yes or True. We call this as class 1 and it is denoted by P(class = 1). If the probability inches closer to one, then we will be more confident about our model that the observation is in class 1, otherwise it is in class 0.\n",
    "\n",
    "***Example:***\n",
    "\n",
    "![example](../data/years-2.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of Logistic Regression\n",
    "\n",
    "\n",
    "The Logistic Regression model requires several key assumptions. These are as follows:-\n",
    "\n",
    "1. Logistic Regression model requires the dependent variable to be binary, multinomial or ordinal in nature.\n",
    "\n",
    "2. It requires the observations to be independent of each other. So, the observations should not come from repeated measurements.\n",
    "\n",
    "3. Logistic Regression algorithm requires little or no multicollinearity among the independent variables. It means that the independent variables should not be too highly correlated with each other.\n",
    "\n",
    "4. Logistic Regression model assumes linearity of independent variables and log odds.\n",
    "\n",
    "5. The success of Logistic Regression model depends on the sample sizes. Typically, it requires a large sample size to achieve the high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Logistic Regression\n",
    "\n",
    "\n",
    "Logistic Regression model can be classified into three groups based on the target variable categories. These three groups are described below:-\n",
    "\n",
    "#### 1. Binary Logistic Regression\n",
    "\n",
    "In Binary Logistic Regression, the target variable has two possible categories. The common examples of categories are yes or no, good or bad, true or false, spam or no spam and pass or fail.\n",
    "\n",
    "\n",
    "#### 2. Multinomial Logistic Regression\n",
    "\n",
    "In Multinomial Logistic Regression, the target variable has three or more categories which are not in any particular order. So, there are three or more nominal categories. The examples include the type of categories of fruits - apple, mango, orange and banana.\n",
    "\n",
    "\n",
    "#### 3. Ordinal Logistic Regression\n",
    "\n",
    "In Ordinal Logistic Regression, the target variable has three or more ordinal categories. So, there is intrinsic order involved with the categories. For example, the student performance can be categorized as poor, average, good and excellent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of the Logistic Regression Algorithm\n",
    "\n",
    "- Logistic regression performs better when the data is linearly separable\n",
    "\n",
    "-    It does not require too many computational resources as itâ€™s highly interpretable\n",
    "\n",
    "-    There is no problem scaling the input featuresâ€”It does not require tuning\n",
    "\n",
    "-    It is easy to implement and train a model using logistic regression\n",
    "\n",
    "-    It gives a measure of how relevant a predictor (coefficient size) is, and its direction of association (positive or negative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using LogisticRegression from sklean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output should be NumPy arrays (instances of the class numpy.ndarray) or similar objects. numpy.arange() creates an array of consecutive, equally-spaced values within a given range. For more information on this function, check the official documentation or NumPy arange(): How to Use np.arange().\n",
    "\n",
    "The array x is required to be two-dimensional. It should have one column for each input, and the number of rows should be equal to the number of observations. To make x two-dimensional, you apply .reshape() with the arguments -1 to get as many rows as needed and 1 to get one column. For more information on .reshape(), you can check out the official documentation. Hereâ€™s how x and y look now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0, tol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above statement creates an instance of LogisticRegression and binds its references to the variable model. LogisticRegression has several optional parameters that define the behavior of the model and approach:\n",
    "\n",
    "- penalty is a string ('l2' by default) that decides whether there is regularization and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.\n",
    "\n",
    "- dual is a Boolean (False by default) that decides whether to use primal (when False) or dual formulation (when True).\n",
    "\n",
    "\n",
    "- tol is a floating-point number (0.0001 by default) that defines the tolerance for stopping the procedure.\n",
    "\n",
    "\n",
    "- C is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.\n",
    "\n",
    "\n",
    "- fit_intercept is a Boolean (True by default) that decides whether to calculate the intercept ð‘â‚€ (when True) or consider it equal to zero (when False).\n",
    "\n",
    "\n",
    "- intercept_scaling is a floating-point number (1.0 by default) that defines the scaling of the intercept ð‘â‚€.\n",
    "\n",
    "\n",
    "- class_weight is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.\n",
    "\n",
    "\n",
    "- random_state is an integer, an instance of numpy.RandomState, or None (default) that defines what pseudo-random number generator to use.\n",
    "\n",
    "\n",
    "- solver is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "\n",
    "\n",
    "- max_iter is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting.\n",
    "\n",
    "\n",
    "- multi_class is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.\n",
    "\n",
    "\n",
    "- verbose is a non-negative integer (0 by default) that defines the verbosity for the 'liblinear' and 'lbfgs' solvers.\n",
    "\n",
    "\n",
    "- warm_start is a Boolean (False by default) that decides whether to reuse the previously obtained solution.\n",
    "\n",
    "\n",
    "- n_jobs is an integer or None (default) that defines the number of parallel processes to use. None usually means to use one core, while -1 means to use all available cores.\n",
    "\n",
    "\n",
    "- l1_ratio is either a floating-point number between zero and one or None (default). It defines the relative importance of the L1 part in the elastic-net regularization.\n",
    "\n",
    "You should carefully match the solver and regularization method for several reasons:\n",
    "\n",
    "\n",
    "- 'liblinear' solver doesnâ€™t work without regularization.\n",
    "\n",
    "- 'newton-cg', 'sag', 'saga', and 'lbfgs' donâ€™t support L1 regularization.\n",
    "\n",
    "- 'saga' is the only solver that supports elastic-net regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear', tol=0.1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can quickly get the attributes of your model. For example, the attribute .classes_ represents the array of distinct values that y takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example of binary classification, and y can be 0 or 1, as indicated above.\n",
    "\n",
    "You can also get the value of the slope ð‘â‚ and the intercept ð‘â‚€ of the linear function ð‘“ like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0294685])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49915757]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, ð‘â‚€ is given inside a one-dimensional array, while ð‘â‚ is inside a two-dimensional array. You use the attributes .intercept_ and .coef_ to get these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `predict_proba()` method\n",
    "\n",
    "`predict_proba` method gives the probabilities for the target variable(0 and 1) in this case, in array form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73681284, 0.26318716],\n",
       "       [0.62955563, 0.37044437],\n",
       "       [0.50778771, 0.49221229],\n",
       "       [0.38508873, 0.61491127],\n",
       "       [0.27544658, 0.72455342],\n",
       "       [0.1875027 , 0.8124973 ],\n",
       "       [0.12287554, 0.87712446],\n",
       "       [0.07837492, 0.92162508],\n",
       "       [0.04908869, 0.95091131],\n",
       "       [0.03038501, 0.96961499]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the matrix above, each row corresponds to a single observation. The first column is the probability of the predicted output being zero, that is 1 - ð‘(ð‘¥). The second column is the probability that the output is one, or ð‘(ð‘¥).\n",
    "\n",
    "**`prepict()` method**\n",
    "\n",
    "You can get the actual predictions, based on the probability matrix and the values of ð‘(ð‘¥), with .predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1],\n",
       "       [0, 6]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained matrix shows the following:\n",
    "\n",
    "- Three true negative predictions: The first three observations are zeros predicted correctly.\n",
    "- No false negative predictions: These are the ones wrongly predicted as zeros.\n",
    "- One false positive prediction: The fourth observation is a zero that was wrongly predicted as one.\n",
    "- Six true positive predictions: The last six observations are ones predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y, model.predict(x))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.93      0.88      0.89        10\n",
      "weighted avg       0.91      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.51335372])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.12066084]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97106534, 0.02893466],\n",
       "       [0.9162684 , 0.0837316 ],\n",
       "       [0.7810904 , 0.2189096 ],\n",
       "       [0.53777071, 0.46222929],\n",
       "       [0.27502212, 0.72497788],\n",
       "       [0.11007743, 0.88992257],\n",
       "       [0.03876835, 0.96123165],\n",
       "       [0.01298011, 0.98701989],\n",
       "       [0.0042697 , 0.9957303 ],\n",
       "       [0.00139621, 0.99860379]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0],\n",
       "       [0, 6]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
